---
title: "HarvardX: PH125.9x Data Science  \n   MovieLens Rating Prediction Project"
author: "Sakshi Gupta"
date: "16/11/2020"
output: 
 pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

# Introduction
This is the report on the movie reccomendation system which recommends the movie based on the rating scale. This is the capstone report of the HarvardX: Data Science- Capstone course

# Objective of the project
Objective of this project is to develop a machine learning model that could predict the user ratings (from 0.5 to 5) using the edx as the train set and validation data set as the test set. 
We will calculate the RMSE (Root Mean Squared Error), which is a frequently used measure of the differences between values predicted by a model or an estimator and the values observed.
The less the value of the RMSE, the more good is the model. 

Formula of RMSE is 
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$


# Data
The original data was obtained from GroupLens research and can be found at
"https://grouplens.org/datasets/movielens/10m/"
This data was provided by the course instrutor in the video

## Loading of Data
The data can be loaded by the below code provided in the course intructions. We will split the complete data into edx set and validation set. Validation set will be 10% of the total data.
we will train our model on the edx data set and test it on the Validation data set
Validation set will be used at the final stage to validate the model perfromance.

```{r code provided in the course intructions}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

#loading libraries

library(tidyverse)
library(caret)
library(data.table)
library(dplyr)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

#downloading the dataset
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                            title = as.character(title),
                                            genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                            title = as.character(title),
                                            genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
      semi_join(edx, by = "movieId") %>%
      semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```


Is is important to check for any NA value present in both edx and Validation data

```{r}
anyNA(edx)
anyNA(validation)

```

# Analysis
## Data Exploration Analysis
Before proceeding ahead, we will analyse the data set structure.

```{r }
str(edx)
str(validation)
```

using $Summary()$, we get the complete insights of the dataset, including mean,mediam, min and max values

```{r}
summary(edx)
```

Count for movies and users in the dataset

```{r }
edx %>% summarise(userscount = n_distinct(userId), moviescount = n_distinct(movieId))
```

The total number of unique users and movies are 69878 and 10677 respectively.

The maximum movies received the rating 4 followed by rating 3 and 5. 

```{r }
edx %>% group_by(rating) %>%
  summarise(count = n()) %>%
  top_n(5) %>% arrange(desc(count))
```

The top 10 most rated movies are-

```{r }
edx  %>% group_by(movieId, title) %>% summarise(count = n()) %>% arrange(desc(count)) %>% top_n(5) 
```


We plot the number of ratings per movie

```{r }
edx %>% count(movieId) %>% ggplot(aes(n)) + 
  geom_histogram(color = "black" , fill= "light blue") + scale_x_log10() +
  ggtitle("Rating per movie") + theme_gray()
```

The users who rated the most of the movies-

```{r }
edx %>% group_by(userId) %>%
  summarise(count = n()) %>% arrange(desc(count)) %>% top_n(10)
```

We plot the number of ratings per user

``` {}
edx %>% count(userId) %>% ggplot(aes(n)) + geom_histogram(color = "black", fill = "light blue") +
  scale_x_log10()+ ggtitle("Ratings per user") + theme_gray()
```

As observed many movies are categorized as more than 1 genre. Before calculating the highly rated genres, we have to seperate th genres on '|'

The most rated genres are 

```{r}
edx %>% separate_rows(genres , sep = "\\|") %>%
  group_by(genres) %>% summarise(count = n()) %>%
  arrange(desc(count)) %>% top_n(10)
```

We can see that Drama , Comedy and Action are the most rated genres


# Model Building
## RMSE Calcultion

we will now write the loss-function that will compute the RMSE.

RMSE is the measure of our model accuracy.
It is the error we make when predicting the movie rating. The lesser the RMSE , the lesser the error. 
In this case, if the RMSE is more than 1, the error in predicting the rating of movie is of 1 rating.

$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$

RMSE function is 

```{r}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((predicted_ratings - true_ratings)^2, na.rm = TRUE))
}
```


## First RMSE - Average movie rating model

The first basic model is where we compute the mean rating for the complete data set. This predict the same rating for all the movies. The expected rating of the underlying dataset is between 3 and 4. 

We start building the model by the simplest possible reccomendation system where the we predict the same rating for all the movies, regardless of other factors like users who gave it or which movie received more ratings. 

```{r}
mu_hat <- mean(edx$rating)
mu_hat
naive_rmse <- RMSE(validation$rating, mu_hat)
naive_rmse
```

Lets save this RMSE in a table and keep on adding more RMSE to this table to analyse the best model

```{r}
rmse_results <- data_frame(method = "Average model approach", RMSE= naive_rmse)
rmse_results %>% knitr::kable()
```

Now we have got our baseline RMSE to compare with the other model results

In order to do better than simply predicting the average rating, we will consider some of the insights we gained during the exploratory data analysis.

## Second Model - Movie effect model

To improve the accuracy of the prediction, we will focus on the fact that some movies receive more ratings than others.

Higher ratings are mostly linked to popular movies among users.
Here we are taking into account the effect of b_i, where we will be subtracting the mean of rating received by a particular movie from the actual rating of that movie

$$Y_{u, i} = \mu +b_{i}+ \epsilon_{u, i}$$

```{r}
movie_avgs <- edx %>%
  group_by(movieId) %>% summarise(b_i = mean(rating - mu_hat))
```


We plot this and analyse

```{r }
movie_avgs %>%
   ggplot(aes(b_i, color = I("black") ) ) +
  geom_histogram(bins= 10) + 
  labs(title = "Number of movies with the computed b_i") +
  ylab("Number of movies")
```

Now lets see how the prediction improves after altering the equation $Y~u,i~ = ?? + b~i$

```{r }
predicted_ratings <- mu_hat + validation %>% left_join(movie_avgs , by = 'movieId') %>%
  pull(b_i)
```

The RMSE of second model (movie effect model) is 

```{r }
rmse_with_bi <- RMSE(predicted_ratings, validation$rating)
rmse_with_bi
```

Adding this RMSE to the results table

```{r }
rmse_results <- bind_rows(rmse_results, data_frame(method = "Movie effect model" , RMSE = rmse_with_bi))
rmse_results %>% knitr::kable()
```

## Third Model - Movie and User effect model

Here we are taking into account the effect of user also along with the movie

```{r }
user_avgs <- edx %>% left_join(movie_avgs, by= 'movieId') %>%
  group_by(userId) %>% summarise(b_u = mean(rating - mu_hat - b_i))
```

Now lets plot this observation

```{r }
user_avgs %>% ggplot(aes(b_u, color= I("black"))) + geom_histogram(bins = 10) + labs("Number of movies with computed b_u") +
  ylab("Number of movies")
```


Now lets see how the prediction improves after altering the equation $Y~u,i~ = ?? + b~i +b~u$

```{r }
predicted_ratings <- validation %>% left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>% mutate(pred = mu_hat + b_i + b_u) %>%
  pull(pred)
```

The RMSE of third model (movie + user effect model) is 

```{r }
rmse_with_bi_bu <- RMSE(predicted_ratings, validation$rating)
rmse_with_bi_bu
```

Adding this third model RMSE to the results table

```{r }
rmse_results <- bind_rows(rmse_results, data_frame(method = "Movie and User effect model", RMSE = rmse_with_bi_bu))
rmse_results %>% knitr::kable()
```


Here we can see that considering the movie and user effects helps in giving better prediction. 
Let us now apply this model to the validation set to validate our model and it's accuracy

```{r }
validation_pred_rating <- validation %>%
  left_join(movie_avgs, by= 'movieId') %>%
  left_join(user_avgs, by= 'userId') %>% 
  mutate(pred = mu_hat + b_i+ b_u) %>%
  pull(pred)

```

RMSE of the validation set

```{r }
rmse_validation <- RMSE(validation_pred_rating, validation$rating)
```

Save this rmse to the results table

```{r }
rmse_results <- bind_rows(rmse_results, data_frame(method = "RMSE of Validation set", RMSE = rmse_validation))
rmse_results %>% knitr::kable()
```

## Regularization

Regularizing the movie and user effect. We will use lambda as the tunning parameter, and cross-validation to choose the best tuning parameter.

```{r }
lambdas <- seq(0,10,0.25)
```

Now we will find bias value-  $b_i$ and $b_u$ for every lambda value

```{r }
rmses <- sapply(lambdas, function(l){
  
  mu <- mean(edx$rating)
  
  b_i <- edx %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- edx %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  
  predicted_ratings <- 
    validation %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, validation$rating))
})
```


Plot rmses vs lambda to select the optimal value of lambda

```{r }
qplot(lambdas, rmses)  

```

The optimal value of lambda is 

```{r }
lambda <- lambdas[which.min(rmses)]
lambda
```

Save this result in the rmse_results table

```{r }
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regularized movie and user effect model",  
                                     RMSE = min(rmses)))
```



# Results

The RMSE values of all the represented models are the following:

```{r }
rmse_results %>% knitr::kable()
```

We therefore observe that the lowet value of the RMSE is 0.8648170

# Conclusion

So here in this project we build a machine learning model to predict the movie rating using the dataset provided by Movielens

So our final model for the movie reccomendation system is :

$$Y_{u, i} = \mu + b_{i} + b_{u} + \epsilon_{u, i}$$

Here we observed that the regularized model including the user and movie effect gave us the lowest RMSE value and is  the optimal model i.e: 0.8648170

We can further improve the RMSE by adding other effects like  genre, year etc.

This model works well if the average user does not rate any popular movie with large positive $b_i$ by disliking a popular movie. 


